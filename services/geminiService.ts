import { GoogleGenAI, Modality, Part } from "@google/genai";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
    throw new Error("API_KEY environment variable not set");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

export async function generateArchitecturalImage(imagePart: Part, textPrompt: string): Promise<string> {
    const textPart = { text: textPrompt };

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: {
                parts: [imagePart, textPart],
            },
            config: {
                responseModalities: [Modality.IMAGE],
            },
        });
        
        const candidate = response.candidates?.[0];

        const generatedPart = candidate?.content?.parts?.find(
            (part) => part.inlineData && part.inlineData.mimeType.startsWith('image/')
        );

        if (generatedPart?.inlineData?.data) {
            const mimeType = generatedPart.inlineData.mimeType;
            const base64Image = generatedPart.inlineData.data;
            return `data:${mimeType};base64,${base64Image}`;
        } else {
            console.error("No image part found in API response:", JSON.stringify(response, null, 2));
            const finishReason = candidate?.finishReason;
            if (finishReason === 'NO_IMAGE') {
                 throw new Error("The AI model chose not to generate an image for this prompt. This can happen with complex requests. Please try a different prompt.");
            }
            if (finishReason === 'SAFETY') {
                 throw new Error("The request was blocked by safety filters. Please modify your prompt or use a different image.");
            }
            throw new Error("No image was generated by the API.");
        }
    } catch (error) {
        console.error("Error generating image with Gemini API:", error);
        if (error instanceof Error) {
            try {
                // Attempt to parse a JSON error message from the API
                const parsedError = JSON.parse(error.message);
                if (parsedError.error && parsedError.error.message) {
                    throw new Error(`Failed to generate image: ${parsedError.error.message}`);
                }
            } catch (parseError) {
                // Not a JSON error, throw original message
                throw new Error(`Failed to generate image: ${error.message}`);
            }
        }
        throw new Error("Failed to generate image. Please check the console for more details.");
    }
}

export async function analyzeBuilding(imagePart: Part): Promise<string> {
    const textPart = { text: "Provide a detailed architectural analysis of this building. Discuss its style, materials, potential era of construction, and notable features in well-structured markdown format." };
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: { parts: [imagePart, textPart] },
    });
    return response.text;
}

// FIX: Implement and export generateVideoFromImage for video generation.
export async function generateVideoFromImage(
    imagePart: Part, 
    prompt: string, 
    aspectRatio: '16:9' | '9:16',
    onProgress: (progress: string) => void
): Promise<string> {
    if (!imagePart.inlineData) {
        throw new Error("Invalid image part provided for video generation.");
    }
    onProgress('Starting video generation...');
    let operation = await ai.models.generateVideos({
        model: 'veo-3.1-fast-generate-preview',
        prompt: prompt,
        image: {
            imageBytes: imagePart.inlineData.data,
            mimeType: imagePart.inlineData.mimeType,
        },
        config: {
            numberOfVideos: 1,
            resolution: '720p',
            aspectRatio: aspectRatio,
        }
    });

    onProgress('Processing video... this may take a few minutes.');
    while (!operation.done) {
        await new Promise(resolve => setTimeout(resolve, 10000));
        onProgress('Checking video status...');
        operation = await ai.operations.getVideosOperation({ operation: operation });
    }

    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) {
        throw new Error("Video generation completed, but no download link was found.");
    }

    onProgress('Fetching generated video...');
    const response = await fetch(`${downloadLink}&key=${API_KEY}`);
    if (!response.ok) {
        throw new Error(`Failed to download video: ${response.statusText}`);
    }
    const videoBlob = await response.blob();
    onProgress('Video ready.');
    return URL.createObjectURL(videoBlob);
}

// FIX: Implement and export generateDescriptionForNarration for text generation.
export async function generateDescriptionForNarration(imagePart: Part): Promise<string> {
    const textPart = { text: "Based on this aerial image of a building, write a short, elegant, and descriptive narration script (around 50-70 words) for a video showcase. Focus on the building's key architectural features and its relationship with the surrounding environment." };
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: { parts: [imagePart, textPart] },
    });
    return response.text;
}

// FIX: Implement and export generateSpeechFromText for text-to-speech.
export async function generateSpeechFromText(text: string): Promise<string> {
    try {
        const response = await ai.models.generateContent({
            model: "gemini-2.5-flash-preview-tts",
            contents: [{ parts: [{ text }] }],
            config: {
                responseModalities: [Modality.AUDIO],
                speechConfig: {
                    voiceConfig: {
                        prebuiltVoiceConfig: { voiceName: 'Kore' },
                    },
                },
            },
        });

        const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
        if (base64Audio) {
            return base64Audio;
        } else {
            console.error("No audio part found in API response:", JSON.stringify(response, null, 2));
            throw new Error("No audio was generated by the API.");
        }
    } catch(error) {
        console.error("Error generating speech with Gemini API:", error);
        if (error instanceof Error) {
            throw new Error(`Failed to generate audio: ${error.message}`);
        }
        throw new Error("Failed to generate audio. Please check the console for more details.");
    }
}

// FIX: Implement and export generateMultiViewNarrationScript for text generation.
export async function generateMultiViewNarrationScript(imagePart: Part): Promise<string> {
    const textPart = { text: "You are an architectural storyteller. Based on the provided image of a building, write a compelling and descriptive narration script (around 100-150 words). The script should guide a viewer through several perspectives: an aerial view, a side view, a dramatic low-angle 'ant's eye' view, and finally, a glimpse of a potential interior space. Weave a narrative that highlights the building's design, materials, and overall feeling." };
    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: { parts: [imagePart, textPart] },
    });
    return response.text;
}